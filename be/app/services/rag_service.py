"""
RAG (Retrieval-Augmented Generation) Service
Combines Milvus vector search with Azure OpenAI for intelligent Q&A
"""

import os
import logging
from typing import List, Dict, Any, Optional
from .milvus_service import MilvusService
from .openai_service import openai_service

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RAGService:
    def __init__(self):
        """Initialize RAG service with Milvus and Azure OpenAI"""
        
        # Initialize Milvus
        self.milvus = MilvusService()
        self.milvus_connected = False
        
        # Use OpenAI service for chat completions
        
        # RAG parameters
        self.top_k = 5  # Number of documents to retrieve
        self.max_context_length = 4000  # Maximum context characters
        

    
    def connect_milvus(self) -> bool:
        """Connect to Milvus vector database"""
        try:
            if self.milvus.connect():
                # Load collection
                from pymilvus import Collection
                self.milvus.collection = Collection("document_embeddings")
                if self.milvus.load_collection():
                    self.milvus_connected = True
                    logger.info("Connected to Milvus successfully")
                    return True
            
            logger.error("Failed to connect to Milvus")
            return False
            
        except Exception as e:
            logger.error(f"Error connecting to Milvus: {e}")
            return False
    
    def retrieve_documents(self, query: str, top_k: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        Retrieve relevant documents from Milvus
        
        Args:
            query: User question/query
            top_k: Number of documents to retrieve
            
        Returns:
            List of relevant documents with metadata
        """
        if not self.milvus_connected:
            logger.error("Milvus not connected")
            return []
        
        k = top_k or self.top_k
        
        try:
            results = self.milvus.search_similar(query, top_k=k)
            logger.info(f"Retrieved {len(results)} documents for query: {query}")
            return results
            
        except Exception as e:
            logger.error(f"Error retrieving documents: {e}")
            return []
    
    def format_context(self, documents: List[Dict[str, Any]]) -> str:
        """
        Format retrieved documents into context string
        
        Args:
            documents: List of retrieved documents
            
        Returns:
            Formatted context string
        """
        if not documents:
            return "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan."
        
        context_parts = []
        current_length = 0
        
        for doc in documents:
            # Format document info
            doc_info = f"""
TÃ i liá»‡u: {doc['title']}
Pháº§n: {doc['section']}
Ná»™i dung: {doc['content']}
---
"""
            
            # Check if adding this document exceeds max length
            if current_length + len(doc_info) > self.max_context_length:
                break
            
            context_parts.append(doc_info)
            current_length += len(doc_info)
        
        return "\n".join(context_parts)
    
    def generate_response(self, query: str, context: str) -> str:
        """
        Generate response using OpenAI with context
        
        Args:
            query: User question
            context: Retrieved context from documents
            
        Returns:
            Generated response
        """
        if not openai_service.enabled:
            return "Xin lá»—i, dá»‹ch vá»¥ AI hiá»‡n khÃ´ng kháº£ dá»¥ng."
        
        try:
            # Create system prompt
            system_prompt = """Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn vá» thá»§ tá»¥c hÃ nh chÃ­nh cÃ´ng dÃ¢n Viá»‡t Nam. 
HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p má»™t cÃ¡ch chÃ­nh xÃ¡c, chi tiáº¿t vÃ  há»¯u Ã­ch.

Quy táº¯c:
1. Chá»‰ sá»­ dá»¥ng thÃ´ng tin tá»« tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p
2. Náº¿u khÃ´ng cÃ³ thÃ´ng tin liÃªn quan, hÃ£y nÃ³i ráº±ng báº¡n khÃ´ng cÃ³ Ä‘á»§ thÃ´ng tin
3. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t
4. Cáº¥u trÃºc cÃ¢u tráº£ lá»i rÃµ rÃ ng, dá»… hiá»ƒu
5. Náº¿u cÃ³ quy trÃ¬nh, hÃ£y liá»‡t kÃª tá»«ng bÆ°á»›c cá»¥ thá»ƒ"""
            
            # Create user prompt
            user_prompt = f"""
ThÃ´ng tin tham kháº£o:
{context}

CÃ¢u há»i: {query}

HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn thÃ´ng tin trÃªn."""
            
            # Prepare messages for OpenAI
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            # Call OpenAI
            response = openai_service.chat_completion(messages)
            
            return response
            
        except Exception as e:
            logger.error(f"Error generating response: {e}")
            return f"Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra khi táº¡o cÃ¢u tráº£ lá»i: {str(e)}"
    
    def query(self, question: str, include_sources: bool = True) -> Dict[str, Any]:
        """
        Main RAG query function
        
        Args:
            question: User question
            include_sources: Whether to include source documents
            
        Returns:
            Dictionary with response and metadata
        """
        try:
            # Step 1: Retrieve relevant documents
            documents = self.retrieve_documents(question)
            
            if not documents:
                return {
                    "response": "Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan Ä‘áº¿n cÃ¢u há»i cá»§a báº¡n.",
                    "sources": [],
                    "confidence": 0.0
                }
            
            # Step 2: Format context
            context = self.format_context(documents)
            
            # Step 3: Generate response
            response = self.generate_response(question, context)
            
            # Step 4: Prepare result
            result = {
                "response": response,
                "confidence": documents[0]["score"] if documents else 0.0
            }
            
            if include_sources:
                result["sources"] = [
                    {
                        "title": doc["title"],
                        "section": doc["section"],
                        "file_name": doc["file_name"],
                        "score": doc["score"],
                        "content_preview": doc["content"][:200] + "..." if len(doc["content"]) > 200 else doc["content"]
                    }
                    for doc in documents[:3]  # Top 3 sources
                ]
            else:
                result["sources"] = []
            
            return result
            
        except Exception as e:
            logger.error(f"Error in RAG query: {e}")
            return {
                "response": f"Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra: {str(e)}",
                "sources": [],
                "confidence": 0.0
            }
    
    def get_stats(self) -> Dict[str, Any]:
        """Get service statistics"""
        stats = {
            "milvus_connected": self.milvus_connected,
            "openai_available": openai_service.enabled,
            "collection_size": 0,
            "embedding_model": openai_service.embedding_model,
            "chat_model": openai_service.chat_model
        }
        
        if self.milvus_connected:
            stats["collection_size"] = self.milvus.get_collection_stats()
        
        return stats

# Example usage
if __name__ == "__main__":
    # Initialize RAG service
    rag = RAGService()
    
    # Connect to Milvus
    if not rag.connect_milvus():
        print("Failed to connect to Milvus")
        exit(1)
    
    # Test queries
    test_queries = [
        "Thá»§ tá»¥c Ä‘Äƒng kÃ½ thÆ°á»ng trÃº nhÆ° tháº¿ nÃ o?",
        "Cáº§n nhá»¯ng giáº¥y tá» gÃ¬ Ä‘á»ƒ lÃ m cÄƒn cÆ°á»›c cÃ´ng dÃ¢n?",
        "Quy trÃ¬nh xin cáº¥p há»™ chiáº¿u má»›i?",
        "Thá»i gian xá»­ lÃ½ há»“ sÆ¡ lÃ  bao lÃ¢u?"
    ]
    
    print("=== RAG Service Test ===")
    for query in test_queries:
        print(f"\nğŸ” CÃ¢u há»i: {query}")
        result = rag.query(query)
        print(f"ğŸ“ Tráº£ lá»i: {result['response']}")
        print(f"ğŸ¯ Äá»™ tin cáº­y: {result['confidence']:.4f}")
        
        if result['sources']:
            print("ğŸ“š Nguá»“n tham kháº£o:")
            for i, source in enumerate(result['sources'], 1):
                print(f"   {i}. {source['title']} - {source['section']} (Score: {source['score']:.4f})")
        
        print("-" * 60)
